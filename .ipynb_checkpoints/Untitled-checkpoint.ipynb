{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abf9f64d-f789-493b-af6c-b7f0bc422878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/imdb\\Test.csv\n",
      "./data/imdb\\Train.csv\n",
      "./data/imdb\\Valid.csv\n",
      "I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.\n",
      "0\n",
      "['I', 'grew', 'up', '(', 'b', '.', '1965', ')', 'watching', 'and', 'loving', 'the', 'Thunderbirds', '.', 'All', 'my', 'mates', 'at', 'school', 'watched', '.', 'We', 'played', '``', 'Thunderbirds', \"''\", 'before', 'school', ',', 'during', 'lunch', 'and', 'after', 'school', '.', 'We', 'all', 'wanted', 'to', 'be', 'Virgil', 'or', 'Scott', '.', 'No', 'one', 'wanted', 'to', 'be', 'Alan', '.', 'Counting', 'down', 'from', '5', 'became', 'an', 'art', 'form', '.', 'I', 'took', 'my', 'children', 'to', 'see', 'the', 'movie', 'hoping', 'they', 'would', 'get', 'a', 'glimpse', 'of', 'what', 'I', 'loved', 'as', 'a', 'child', '.', 'How', 'bitterly', 'disappointing', '.', 'The', 'only', 'high', 'point', 'was', 'the', 'snappy', 'theme', 'tune', '.', 'Not', 'that', 'it', 'could', 'compare', 'with', 'the', 'original', 'score', 'of', 'the', 'Thunderbirds', '.', 'Thankfully', 'early', 'Saturday', 'mornings', 'one', 'television', 'channel', 'still', 'plays', 'reruns', 'of', 'the', 'series', 'Gerry', 'Anderson', 'and', 'his', 'wife', 'created', '.', 'Jonatha', 'Frakes', 'should', 'hand', 'in', 'his', 'directors', 'chair', ',', 'his', 'version', 'was', 'completely', 'hopeless', '.', 'A', 'waste', 'of', 'film', '.', 'Utter', 'rubbish', '.', 'A', 'CGI', 'remake', 'may', 'be', 'acceptable', 'but', 'replacing', 'marionettes', 'with', 'Homo', 'sapiens', 'subsp', '.', 'sapiens', 'was', 'a', 'huge', 'error', 'of', 'judgment', '.']\n",
      "           .          the           of            I          and Thunderbirds       school           to           be            a \n",
      "          17            6            5            3            3            3            3            3            3            3 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<CategorizedPlaintextCorpusReader in 'C:\\\\Users\\\\Elias\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download([\"movie_reviews\"])\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./data/imdb'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        print(path)\n",
    "df_test = df = pd.read_csv('./data/imdb/Test.csv')\n",
    "df_train = df = pd.read_csv('./data/imdb/Train.csv')\n",
    "df_valid = df = pd.read_csv('./data/imdb/Valid.csv')\n",
    "df_test.head()\n",
    "df_train.head()\n",
    "df_valid.head()\n",
    "stopwords = \"\"\n",
    "#stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "#stopwords.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "for i, row in df_train.iterrows():\n",
    "    print(row.text)\n",
    "    print(row.label)\n",
    "    words = [w for w in nltk.word_tokenize(row.text) if w.lower() not in stopwords]\n",
    "    print(words)\n",
    "\n",
    "    fd = nltk.FreqDist(words)\n",
    "    fd.tabulate(10)\n",
    "    \n",
    "    break\n",
    "# Separate positive and negative texts\n",
    "positive_texts = df[df['label'] == 'positive']\n",
    "negative_texts = df[df['label'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef864e9-345b-4ac2-849f-b3eedc71081b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
