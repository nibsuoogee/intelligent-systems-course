{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deb6dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task:\n",
    "# An SVD Recommender that predicts the rating a user will give to a movie\n",
    "# based on the user's own ratings and other users' rating data.\n",
    "\n",
    "# Use only 'rating' as the data, avoid 'tags' and 'genre'\n",
    "\n",
    "# 80/20, train/test split. Additionally, do a temporal split. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98290a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from numpy.linalg import svd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0f52595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ascii_percentage_bar(value):\n",
    "    filled_length = int(value *  100)\n",
    "    empty_length = 100 - filled_length\n",
    "\n",
    "    bar = '[' + '%' * filled_length + ']'\n",
    "    #  + '_' * empty_length\n",
    "    \n",
    "    print(bar, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f7450c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Movies'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ratings'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "movies = 'data/movielens-latest-small/movies.csv'\n",
    "ratings = 'data/movielens-latest-small/ratings.csv'\n",
    "\n",
    "# to dataframes\n",
    "df_movies = pd.read_csv(movies)\n",
    "df_ratings = pd.read_csv(ratings)\n",
    "\n",
    "# inspect them\n",
    "display('Movies')\n",
    "display(df_movies.head())\n",
    "display('Ratings')\n",
    "display(df_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd207677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows = 80668\n",
      "Testing rows = 20168\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 40665 40666 40667]\n",
      "  Test:  index=[40668 40669 40670 ... 60665 60666 60667]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 60665 60666 60667]\n",
      "  Test:  index=[60668 60669 60670 ... 80665 80666 80667]\n",
      "Training rows temporal split = 60668\n",
      "Testing rows temporal split = 20000\n"
     ]
    }
   ],
   "source": [
    "# 80/20, train/test split\n",
    "df_ratings_x = df_ratings[['userId', 'movieId', 'timestamp']]\n",
    "df_ratings_y = df_ratings[['rating', 'timestamp']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_ratings_x, df_ratings_y, test_size=0.2, random_state=1)\n",
    "print(f\"Training rows = {x_train.shape[0]}\")\n",
    "print(f\"Testing rows = {x_test.shape[0]}\")\n",
    "\n",
    "#display(x_train.head())\n",
    "#display(x_test.head())\n",
    "#display(y_train.head())\n",
    "#display(y_test.head())\n",
    "\n",
    "# temporal split\n",
    "tscv = TimeSeriesSplit(n_splits=2, test_size=20000)\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(x_train, y_train)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "print(f\"Training rows temporal split = {train_index.shape[0]}\")\n",
    "print(f\"Testing rows temporal split = {test_index.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf21028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consider reviews from users with more than 50 reviews\n",
    "#usercount = df_ratings[['movieId','userId']].groupby('userId').count()\n",
    "#display(usercount.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7807a73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4. , 0. , 4. , ..., 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        ...,\n",
       "        [2.5, 2. , 2. , ..., 0. , 0. , 0. ],\n",
       "        [3. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        [5. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source for SVD stuff: https://machinelearningmastery.com/using-singular-value-decomposition-to-build-a-recommender-system/\n",
    "# Build a pivot table with movieIds as columns \n",
    "# and users and their ratings as rows\n",
    "rating_matrix = df_ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\").fillna(0)\n",
    "#display(rating_matrix.head())\n",
    "matrix = rating_matrix.values\n",
    "matrix = np.matrix(matrix)\n",
    "display(matrix)\n",
    "#matrix = np.mat([[5, 5, 3, 0, 5, 5], [5, 0, 4, 0, 4, 4], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]])\n",
    "#display(matrix)\n",
    "#matrix = np.mat([[4, 0, 4, 0, 0, 4], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]])\n",
    "#display(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c64d7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular value decomposition\n",
    "U, S, VT = np.linalg.svd(matrix.T, full_matrices=False)\n",
    "# We know that the columns of vh are movies\n",
    "# The rows of u are users\n",
    "\n",
    "V = VT.T\n",
    "Sigma = np.diag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf5a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v,u):\n",
    "    return (v @ u)/ (np.linalg.norm(v) * np.linalg.norm(u))\n",
    "\n",
    "def rmse_function(v, u):\n",
    "    return np.sqrt(np.mean((v - u) ** 2))\n",
    "\n",
    "def squared_distance(v, u):\n",
    "    return np.sum((v - u) ** 2)\n",
    "\n",
    "def manhattan_distance(v, u):\n",
    "    return np.sum(np.abs(v - u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b33e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means RMSE Clustering \n",
    "# select k random data points (user indexes in u) as initial cluster centers C_1, ..., C_k\n",
    "\n",
    "def initialize_centroids(data_points, k, seed = None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    # Select k random indexes from the data points list\n",
    "    centroid_indexes = random.sample(range(data_points.shape[0]), k)\n",
    "    \n",
    "    # Construct the list of centroids using the selected indexes\n",
    "    centroids = [copy.deepcopy(data_points[i]) for i in centroid_indexes]\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def assign_point_to_centroid(user_index, point, centroid_index, assignments):\n",
    "    if centroid_index not in assignments:\n",
    "        assignments[centroid_index] = [(user_index, point)]\n",
    "    else:\n",
    "        assignments[centroid_index].append((user_index, point))\n",
    "\n",
    "def update_centroid_position(centroid, new_position):\n",
    "    centroid[:] = new_position\n",
    "    \n",
    "def average_point(points):\n",
    "    # Extract the points (user points) from the tuples\n",
    "    user_points = [point[1] for point in points]\n",
    "    \n",
    "    # Convert the list of points to a NumPy array\n",
    "    points_array = np.array(user_points)\n",
    "\n",
    "    # Compute the mean along each dimension\n",
    "    average = np.mean(points_array, axis=0)\n",
    "    \n",
    "    return average\n",
    "\n",
    "def k_means(u, k, max_iterations, seed, threshold):\n",
    "    assignments = {}\n",
    "    num_datapoints = u.shape[0]\n",
    "    \n",
    "    centroids = initialize_centroids(u, k, seed)\n",
    "\n",
    "    for iteration in range(1, max_iterations):\n",
    "        #print()\n",
    "        #print(\" Iteration \", i, end=\"\")\n",
    "\n",
    "        assignments = {}\n",
    "        non_converged_centroids = copy.deepcopy(k)\n",
    "        \n",
    "        # for each p (user) in u, map p_i to its nearest cluster center C_j \n",
    "        for user_index, p in enumerate(u):\n",
    "            # Find the closest centroid to the current data point\n",
    "            #closest_centroid_index, _ = max(enumerate(centroids), key=lambda c: cosine_similarity(p, c[1]))\n",
    "            closest_centroid_index, _ = max(enumerate(centroids), key=lambda c: cosine_similarity(p, c[1]))\n",
    "\n",
    "            assign_point_to_centroid(user_index, p, closest_centroid_index, assignments)\n",
    "\n",
    "        for index, centroid in enumerate(centroids):\n",
    "            # Update centroid position by taking the mean of assigned data points\n",
    "            \n",
    "            assigned_points = assignments[index]  # get all data points assigned to a centroid\n",
    "            if assigned_points:\n",
    "                \n",
    "                #draw_ascii_percentage_bar(len(assigned_points) / num_datapoints)\n",
    "                #print(\" C\", index, \", \", len(assigned_points), \" points\")\n",
    "\n",
    "                new_position = average_point(assigned_points)\n",
    "                 # calculate Euclidean distance\n",
    "\n",
    "                distance = np.linalg.norm(centroid - new_position)\n",
    "                \n",
    "                if distance < threshold:\n",
    "                    non_converged_centroids -= 1\n",
    "\n",
    "                update_centroid_position(centroid, new_position)\n",
    "            \n",
    "        if (non_converged_centroids == 0):\n",
    "            print(\"iter: \", iteration, \" ******* CONVERGED ******* \", end=\"\")\n",
    "            break\n",
    "    \n",
    "    total_rmse = 0\n",
    "    for centroid_index, data_points in assignments.items():\n",
    "        squared_distances = 0\n",
    "\n",
    "        for point_index, point in enumerate(data_points):\n",
    "            # calculate squared distancs of each point to its centroid\n",
    "            squared_distances += squared_distance(point[1], centroids[centroid_index])\n",
    "        \n",
    "        # divide the sum of squared distances with the number of points in the centroid\n",
    "        mse = squared_distances / len(centroids[centroid_index])\n",
    "\n",
    "        # take the square root of mse to get rmse\n",
    "        rmse = np.sqrt(mse)\n",
    "        total_rmse += rmse\n",
    "    \n",
    "    # Calculate the average RMSE\n",
    "    average_rmse = total_rmse / len(assignments)\n",
    "    print(\"average_rmse: \", average_rmse)\n",
    "    \n",
    "    #centroids_and_assignments = [(centroids[i], assignments[i]) for i in range(len(centroids))]\n",
    "    centroids_and_assignments = np.array([(centroids[i], assignments[i]) for i in range(len(centroids))], dtype=object)\n",
    "\n",
    "    return centroids_and_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9ed980f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5520\\4293480815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mcentroids_and_assignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'k_means' is not defined"
     ]
    }
   ],
   "source": [
    "max_iterations = 50\n",
    "threshold = 1e-5\n",
    "\n",
    "# Use first 2 singular values. Source: https://www.kaggle.com/code/vincentman0403/recommendation-example-by-svd\n",
    "r = 2\n",
    "\n",
    "# Get approximate U, Sigma, VT\n",
    "Ur = U[:, :r]\n",
    "\n",
    "#print(\"matrix.shape[0]: \", matrix.shape[0])\n",
    "\n",
    "#print(\"Sigma: \", Sigma)\n",
    "\n",
    "Sr = Sigma[:r, :r]\n",
    "Vr = V[:, :r]\n",
    "\n",
    "# use specific start conditions\n",
    "k = 7\n",
    "seed = 0\n",
    "\n",
    "centroids_and_assignments = k_means(Ur, k, max_iterations, seed, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141835f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate similarities to all others users for a single user\n",
    "def get_similarities(target_point, neighbors):\n",
    "    similarities = []\n",
    "\n",
    "    for index, neighbor in enumerate(neighbors):\n",
    "        similarity = cosine_similarity(target_point, neighbor[1])\n",
    "        similarities.append((neighbor, similarity))\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "def predict_rating(centroid_and_assignment, movie_index, ratings_matrix, k=5):\n",
    "    \n",
    "    # Calculate cosine similarity between the centroid and its neighbors\n",
    "    similarities = get_similarities(centroid_and_assignment[0], centroid_and_assignment[1])\n",
    "\n",
    "    # Calculate weighted average of ratings from nearest neighbors\n",
    "    weighted_ratings = 0\n",
    "    total_similarity = 0\n",
    "    for neighbor_index, similarity in enumerate(similarities):\n",
    "\n",
    "        neighbor_similarity = similarity[1]\n",
    "        neighbor_rating = ratings_matrix[similarity[0][0], movie_index]\n",
    "        \n",
    "        if neighbor_rating != 0:  # Ignore if neighbor hasn't rated the movie\n",
    "            weighted_ratings += neighbor_similarity * neighbor_rating\n",
    "            total_similarity += neighbor_similarity\n",
    "            \n",
    "            #print(\"neighbor_similarity: \", neighbor_similarity)\n",
    "            #print(\"neighbor_rating: \", neighbor_rating)\n",
    "            #print(\"weighted rating: \", neighbor_similarity * neighbor_rating)\n",
    "            #print(\"total_similarity: \", total_similarity)\n",
    "            #print()\n",
    "            #break\n",
    "    \n",
    "    # Predict the rating for the target user\n",
    "    if total_similarity != 0:\n",
    "        predicted_rating = weighted_ratings / total_similarity\n",
    "    else:\n",
    "        predicted_rating = 0  # In case none of the nearest neighbors have rated the movie\n",
    "    \n",
    "    return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695f1058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest_centroid_index: 3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 615 is out of bounds for axis 0 with size 610",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16812\\393794950.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"closest_centroid_index:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosest_centroid_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mpredicted_rating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids_and_assignments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclosest_centroid_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted rating:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_rating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16812\\4247209116.py\u001b[0m in \u001b[0;36mpredict_rating\u001b[1;34m(centroid_and_assignment, movie_index, ratings_matrix, k)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mneighbor_similarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mneighbor_rating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneighbor_rating\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Ignore if neighbor hasn't rated the movie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 615 is out of bounds for axis 0 with size 610"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "\n",
    "# for each user, predict rating for every movie\n",
    "\n",
    "# first, find closest centroid\n",
    "# then give prediction based on the centroid\n",
    "\n",
    "# check centroid's distance from actual, if review exists\n",
    "\n",
    "def find_closest_centroid(data_point, centroids):\n",
    "    closest_centroid_distance = np.inf\n",
    "    closest_centroid_index = None\n",
    "    \n",
    "    for centroid_index, centroid in enumerate(centroids):\n",
    "        distance = squared_distance(data_point, centroid)\n",
    "        if distance < closest_centroid_distance:\n",
    "            closest_centroid_distance = distance\n",
    "            closest_centroid_index = centroid_index\n",
    "            \n",
    "    return closest_centroid_index\n",
    "\n",
    "for row in range(0, 100): #u.shape[0]):\n",
    "    centroids = [centroid for centroid, _ in centroids_and_assignments]\n",
    "\n",
    "    closest_centroid_index = find_closest_centroid(Ur[row], centroids)\n",
    "    print(\"closest_centroid_index:\", closest_centroid_index)\n",
    "    \n",
    "    predicted_rating = predict_rating(centroids_and_assignments[closest_centroid_index], movie_index = 0, ratings_matrix = matrix)\n",
    "    print(\"Predicted rating:\", predicted_rating)\n",
    "    print()\n",
    "\n",
    "    #for col in range(0, u.shape[1]):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "734396b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of new user to latent factor =  [[-0.25971894 -0.01331114]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_one():\n",
    "    # new user data point\n",
    "    new = np.full((1, matrix.shape[1]), 3)\n",
    "    newresult = new * Ur * np.linalg.inv(Sr)\n",
    "    \n",
    "    print('Vector of new user to latent factor = ', newresult)\n",
    "    \n",
    "    return\n",
    "    \n",
    "    unique_point = np.array([0.3, 0.8])\n",
    "    \n",
    "    closest_centroid_index = find_closest_centroid(unique_point, centroids)\n",
    "    print(\"closest_centroid_index:\", closest_centroid_index)\n",
    "\n",
    "    predicted_rating = predict_rating(centroids_and_assignments[closest_centroid_index], movie_index = 1, ratings_matrix = matrix)\n",
    "    print(\"Predicted rating:\", predicted_rating)    \n",
    "\n",
    "evaluate_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "\n",
    "# for each user, predict rating for every movie\n",
    "# check distance from actual, if review exists\n",
    "total_error = 0\n",
    "\n",
    "for row in range(0, u.shape[0]):\n",
    "    user_total_error_squared = 0\n",
    "    user_evaluations = 0\n",
    "    \n",
    "    for col in range(0, vh.shape[1]):\n",
    "        predicted_rating = predict_rating(user_index = row, movie_index = col, ratings_matrix = matrix, u = u)\n",
    "        actual_rating = matrix[row][col]\n",
    "        if actual_rating != 0:\n",
    "            user_evaluations += 1\n",
    "            user_total_error_squared += (predicted_rating - actual_rating)**2\n",
    "    \n",
    "    user_total_error = math.sqrt(user_total_error_squared)\n",
    "    print(\"User total error:\", user_total_error)\n",
    "    print(\"User evaluations:\", user_evaluations)\n",
    "    \n",
    "print(\"Total error:\", total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 50\n",
    "threshold = 1e-5\n",
    "\n",
    "# Find converging start conditions, and lowest rmse\n",
    "for seed in range(0, 1):\n",
    "    print(\"seed:\",seed,\" \",end=\"\")\n",
    "    \n",
    "    for k in range(3, 10): \n",
    "        print(\"k:\",k,\" \",end=\"\")\n",
    "        k_means(u, k, max_iterations, seed, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
